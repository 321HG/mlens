{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Ensamble introductory example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ML Ensemble\n",
    "from mlens.ensemble import Ensemble\n",
    "from mlens.metrics import rmse\n",
    "\n",
    "# Base Models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3675)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "First, we need some dummy data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "X = np.random.random((1000, 10))\n",
    "\n",
    "# noisy output, y = x0 * x1 + x2^2 + x3 - x4^(1/4) + e\n",
    "y = X[:, 0] * X[:, 1] + X[:, 2] ** 2 + X[:, 3] - X[:, 4] ** (1 / 4)\n",
    "\n",
    "# Change scales\n",
    "X[:, 0] *= 10\n",
    "X[:, 1] += 10\n",
    "X[:, 2] *= 5\n",
    "X[:, 3] *= 3\n",
    "X[:, 4] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models\n",
    "\n",
    "Next, we need a couple of baseline estimators that we want to combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = Lasso()\n",
    "rf = RandomForestRegressor()\n",
    "kn = KNeighborsRegressor()\n",
    "sv = SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how they perform on the raw input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_models(names, models, parameters):\n",
    "    print('Best cross validated score on raw input data:')\n",
    "    for m, e, p in zip(names, models, parameters):\n",
    "        grid = RandomizedSearchCV(e, param_distributions=p, n_iter=10, cv=10,\n",
    "                                  scoring=rmse, n_jobs=-1)\n",
    "        grid.fit(X, y)\n",
    "        print('%.3f [%s - %r]' % (grid.best_score_, m, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validated score on raw input data:\n",
      "-0.127 [Lasso - {'alpha': 0.00091227021768499955}]\n",
      "-0.282 [Random Forest - {'min_samples_leaf': 7, 'max_depth': 3, 'max_features': 4}]\n",
      "-0.223 [KNN - {'n_neighbors': 8}]\n",
      "-0.111 [SVR - {'C': 15.456574343107798}]\n"
     ]
    }
   ],
   "source": [
    "ls_p = {'alpha': uniform(0.0005, 0.005)}\n",
    "rf_p = {'max_depth': randint(2, 5), 'max_features': randint(3, 5),\n",
    "        'min_samples_leaf': randint(2, 10)}\n",
    "kn_p = {'n_neighbors': randint(5, 20)}\n",
    "sv_p = {'C': uniform(5, 15)}\n",
    "\n",
    "check_models(['Lasso', 'Random Forest', 'KNN', 'SVR'],\n",
    "             (ls, rf, kn, sv), (ls_p, rf_p, kn_p, sv_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if preprocessing the data helps. Now, to avoid data leakages, we need to put our models into pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls = make_pipeline(StandardScaler(), Lasso(alpha=0.001))\n",
    "rf = make_pipeline(StandardScaler(),\n",
    "                   RandomForestRegressor(max_depth=3, max_features=0.7,\n",
    "                                         n_estimators=20, n_jobs=1))\n",
    "kn = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=3))\n",
    "sv = make_pipeline(MinMaxScaler(), SVR(C=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validated score on raw input data:\n",
      "-0.123 [Lasso - {'lasso__alpha': 0.00053995960232497984}]\n",
      "-0.235 [Random Forest - {'randomforestregressor__max_features': 4, 'randomforestregressor__max_depth': 4, 'randomforestregressor__min_samples_leaf': 4}]\n",
      "-0.205 [KNN - {'kneighborsregressor__n_neighbors': 10}]\n",
      "-0.058 [SVR - {'svr__C': 20.691855254901064}]\n"
     ]
    }
   ],
   "source": [
    "ls_p = {'lasso__alpha': uniform(0.0005, 0.005)}\n",
    "rf_p = {'randomforestregressor__max_depth': randint(2, 5),\n",
    "        'randomforestregressor__max_features': randint(3, 5),\n",
    "        'randomforestregressor__min_samples_leaf': randint(2, 10)}\n",
    "kn_p = {'kneighborsregressor__n_neighbors': randint(1, 30)}\n",
    "sv_p = {'svr__C': uniform(1, 20)}\n",
    "\n",
    "check_models(['Lasso', 'Random Forest', 'KNN', 'SVR'],\n",
    "             (ls, rf, kn, sv), (ls_p, rf_p, kn_p, sv_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data helps the Lasso and KNN. The Random Forest is invariant to scale, so no real difference in perforance.\n",
    "The SVR does not improve with standard scaling (not shown), but Min-Max scaling helps. \n",
    "In all, transforming the data helps. However, fitting models in this way is inefficient since several models depend on the same transformation process. However, because there is some variation, it is not so easy as to fit all models\n",
    "on the same preprocessed data. \n",
    "Luckily, the ML-Ensemble library allows us to specify separate preprocessing pipelines with associate base estimators, so we can easily handle such a situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "To improve our score, we build an estimator on top of these baselines in order to try and learn when which model is performing well, and thus leverage the strenght of each model across feature space. The ensemble here has not been optimized to any greater degree: for illustration purposes we'll settle on a configuration somewhat arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix a meta estimator for generating final predictions\n",
    "meta = SVR()\n",
    "\n",
    "# Create base estimators, along with associated preprocessing pipelines\n",
    "base_pipelines = {'sc':\n",
    "                  # standard scaling pipeline\n",
    "                  # we now specify a tuple (preprocessing, estimators)\n",
    "                  # preprocessing is an ordered list of transformers\n",
    "                  # estimators is a list of estimators\n",
    "                  # estimators can be given names by passing tuples\n",
    "                  # ('name', estimator)\n",
    "                  ([StandardScaler()], \n",
    "                   [('ls', Lasso()), ('kn', KNeighborsRegressor())]),\n",
    "                  'mm': # We don't need to name objects\n",
    "                  ([MinMaxScaler()], [SVR()]),\n",
    "                  'np':\n",
    "                  # There is no requirement to preprocess data, in this case\n",
    "                  # just pass an empty list\n",
    "                  ([], [('rf', RandomForestRegressor())])\n",
    "                 }\n",
    "\n",
    "ensemble = Ensemble(meta, # this is the meta estimator\n",
    "                    base_pipelines, # this is the base pipelines\n",
    "                    folds=10, # number of folds used for stacking\n",
    "                    shuffle=True, # whether to shuffle data\n",
    "                    scorer=rmse._score_func, # to get base est test scores\n",
    "                    n_jobs=1,  # joblib can only parallelize the outer loop\n",
    "                               # which is the grid search. Set to 1 for now.\n",
    "                    as_df=True # allows us to look at feature importances\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having instantiated the ensemble, it is easy to map parameters to specific models and pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of parameters:\n",
      "\n",
      "'as_df': True\n",
      "'n_jobs': 1\n",
      "'sc-kn__n_neighbors': 5\n",
      "'meta-svr': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "'scorer': <function rmse_scoring at 0x10e79cea0>\n",
      "'meta-svr__epsilon': 0.1\n",
      "'sc-ls__random_state': None\n",
      "'sc-ls__alpha': 1.0\n",
      "'np-rf__min_samples_split': 2\n",
      "'meta-svr__degree': 3\n",
      "'meta-svr__kernel': 'rbf'\n",
      "'sc-ls__fit_intercept': True\n",
      "'sc-kn__n_jobs': 1\n",
      "'meta-svr__max_iter': -1\n",
      "'sc-kn': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "'sc-standardscaler__copy': True\n"
     ]
    }
   ],
   "source": [
    "print('Sample of parameters:\\n')\n",
    "for i, (key, val) in enumerate(ensemble.get_params().items()):\n",
    "    print(\"%r: %r\" % (key, val))\n",
    "    if i == 15:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can use the sklearn API to update ingoing parameters in any estimator or transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingoing parameter setting:\n",
    "ensemble.get_params()['mm-svr__C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mm',\n",
       " [('svr',\n",
       "   SVR(C=5.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "     kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We update it using the sklearn API\n",
    "ensemble.set_params(**{'mm-svr__C': 5.0})\n",
    "\n",
    "# And now check the nest list \"base_estimators\" that is used for fitting\n",
    "ensemble.base_estimators[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to fit the ensemble, we need to set up the grid search parameter dictionary, which essentially amounts to\n",
    "concatenating the previous dictionaries we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_p = {'sc-ls__alpha': uniform(0.0005, 0.005),\n",
    "        'np-rf__max_depth': randint(2, 6),\n",
    "        'np-rf__max_features': randint(2, 5),\n",
    "        'np-rf__min_samples_leaf': randint(5, 12),\n",
    "        'sc-kn__n_neighbors': randint(6, 12),\n",
    "        'mm-svr__C': uniform(10, 20),\n",
    "        'meta-svr__C': uniform(10, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validated score on raw input data:\n",
      "-0.123 [Lasso - {'lasso__alpha': 0.0015142045314504382}]\n",
      "-0.236 [Random Forest - {'randomforestregressor__max_features': 4, 'randomforestregressor__max_depth': 4, 'randomforestregressor__min_samples_leaf': 5}]\n",
      "-0.207 [KNN - {'kneighborsregressor__n_neighbors': 11}]\n",
      "-0.059 [SVR - {'svr__C': 15.328019931942373}]\n",
      "-0.053 [Ensemble - {'np-rf__min_samples_leaf': 9, 'np-rf__max_features': 4, 'sc-kn__n_neighbors': 9, 'np-rf__max_depth': 4, 'sc-ls__alpha': 0.0014284293508642438, 'meta-svr__C': 16.626146983723014, 'mm-svr__C': 11.834807428701293}]\n"
     ]
    }
   ],
   "source": [
    "check_models(['Lasso', 'Random Forest', 'KNN', 'SVR', 'Ensemble'],\n",
    "             (ls, rf, kn, sv, ensemble), (ls_p, rf_p, kn_p, sv_p, en_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble improves the best base estimator score by 0.01, or by 9%. Given the high accuracy the SVR achieves already, this is a fairly large improvement even with our minor parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a final ensemble\n",
    "\n",
    "With the grid search complete, we have a fair idea of what parameters we want to have. However,\n",
    "during the grid search we deactivated parallelization to avoid clashing with the grid search. \n",
    "Naturally, when we fit the final model, we want to reactivate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting ensemble\n",
      "\n",
      "> fitting meta estimator\n",
      ">> preprocessing folds\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      ">> fitting base estimators\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  40 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
      ">> fitting meta estimator\n",
      "\n",
      "> fitting base estimators\n",
      ">> preprocessing data\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      ">> fitting base estimators\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "Fit complete | 00:00:01\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ensemble(as_df=True,\n",
       "     base_pipelines={'np': ([], [('rf', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=4,\n",
       "           max_features=4, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=9, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "   ...silon=0.1,\n",
       "  gamma='auto', kernel='rbf', max_iter=-1, shrinking=True, tol=0.001,\n",
       "  verbose=False)])},\n",
       "     folds=10,\n",
       "     meta_estimator=SVR(C=16.626146983723014, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto', kernel='rbf', max_iter=-1, shrinking=True, tol=0.001,\n",
       "  verbose=False),\n",
       "     n_jobs=-1, random_state=None,\n",
       "     scorer=<function rmse_scoring at 0x10e79cea0>, shuffle=True,\n",
       "     verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.set_params(**{'np-rf__min_samples_leaf': 9,\n",
    "                       'meta-svr__C': 16.626146983723014,\n",
    "                       'sc-kn__n_neighbors': 9,\n",
    "                       'np-rf__max_features': 4,\n",
    "                       'mm-svr__C': 11.834807428701293,\n",
    "                       'sc-ls__alpha': 0.0014284293508642438,\n",
    "                       'np-rf__max_depth': 4,\n",
    "                       'n_jobs': -1,\n",
    "                       'verbose': 3})\n",
    "ensemble.fit(X[:900], y[:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Estimator scores:\n",
      "sc-kn 0.20796201837\n",
      "np-rf 0.242135163725\n",
      "sc-ls 0.1238471778\n",
      "mm-svr 0.0618138749617\n"
     ]
    }
   ],
   "source": [
    "print('Base Estimator scores:')\n",
    "for est_name, score in ensemble.scores_.items():\n",
    "    print(est_name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.050417414288113208"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(ensemble, X[900:], y[900:])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
