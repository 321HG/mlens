{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Ensamble introducing the Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ML Ensemble\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import rmse\n",
    "\n",
    "# Base Models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3675)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "First, we need some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "X = np.random.random((1000, 10))\n",
    "\n",
    "# noisy output, y = x0 * x1 + x2^2 + x3 - x4^(1/4) + e\n",
    "y = X[:, 0] * X[:, 1] + X[:, 2] ** 2 + X[:, 3] - X[:, 4] ** (1 / 4)\n",
    "\n",
    "# Change scales\n",
    "X[:, 0] *= 10\n",
    "X[:, 1] += 10\n",
    "X[:, 2] *= 5\n",
    "X[:, 3] *= 3\n",
    "X[:, 4] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackling model selection\n",
    "\n",
    "Once a dataset has been at least moderately preprocessed, it's time to see what a learning algortihm can do. Often, we [don't know a priori](https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf) which model will do well and sometimes, we even have different preprocessing pipelines that we would like to compare. This is when the `Evaluator` comes in handy. It allows the user to specify a set of\n",
    "preprocessing cases to compare various estimators against. In the end, everything is summarized neatly in a DataFrame (or dict if you prefer) for a holistic overview. Neat, isn't it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A set of estimators to evaluate\n",
    "ls = Lasso()\n",
    "rf = RandomForestRegressor()\n",
    "kn = KNeighborsRegressor()\n",
    "sv = SVR()\n",
    "\n",
    "# Some parameter distributions that might work well\n",
    "ls_p = {'alpha': uniform(0.0005, 10)}\n",
    "rf_p = {'max_depth': randint(2, 7), 'max_features': randint(3, 10),\n",
    "        'min_samples_leaf': randint(2, 10)}\n",
    "kn_p = {'n_neighbors': randint(2, 20)}\n",
    "sv_p = {'C': uniform(0.01, 20)}\n",
    "\n",
    "# Put it all in neat dictionaries. Note that the keys must match!\n",
    "estimators = {'ls': ls, 'rf': rf, 'kn': kn, 'sv': sv}\n",
    "parameters = {'ls': ls_p, 'rf': rf_p, 'kn': kn_p, 'sv': sv_p}\n",
    "\n",
    "# A set of different preprocessing cases we want to try for each model\n",
    "preprocessing = {'standard_scaler': [StandardScaler()], 'min_max': [MinMaxScaler()], 'None': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initiate the `Evaluator`, simply call the class and pass the data to it along with\n",
    "relevant grid-search information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evals = Evaluator(X, y, preprocessing, rmse, cv=10, verbose=1,\n",
    "                  n_jobs_estimators=-1, n_jobs_preprocessing=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If preprocessing is heavy lifting we can pre-generate folds before evaluating any estimators by calling `preprocess`. (However, by evaluating\n",
    "estimators their folds will automatically be stored, so you can safely run evaluation upon evaluation without having to worry about wading through heavy preprocessing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlens.model_selection.model_selection.Evaluator at 0x1048d7828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate a set of models, simply call the `evaluate` method along with the `estimators` and the `param_dicts`, the dictionary of parameter dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 4 models, with 5 parameter draws and 3 preprocessing options, over 10 CV folds, totalling fits 600.\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:    5.6s finished\n",
      "Evaluation done | 00:00:05\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlens.model_selection.model_selection.Evaluator at 0x1048d7828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.evaluate(estimators, parameters, n_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation made easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a single command we can see the performance of each estimator for each alterative preprocessing pipelines. Just call `summary_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_test_score_mean</th>\n",
       "      <th>best_test_score_std</th>\n",
       "      <th>train_score_mean</th>\n",
       "      <th>train_score_std</th>\n",
       "      <th>score_time</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_estimator</th>\n",
       "      <th>best_draw_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sv_min_max</th>\n",
       "      <td>-0.057709</td>\n",
       "      <td>0.00600658</td>\n",
       "      <td>-0.0536805</td>\n",
       "      <td>0.000789498</td>\n",
       "      <td>0.0355775</td>\n",
       "      <td>{'est__C': 19.8577695762}</td>\n",
       "      <td>Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_standard_scaler</th>\n",
       "      <td>-0.101593</td>\n",
       "      <td>0.0072925</td>\n",
       "      <td>-0.0664077</td>\n",
       "      <td>0.000620663</td>\n",
       "      <td>0.0385854</td>\n",
       "      <td>{'est__C': 9.8360275689}</td>\n",
       "      <td>Pipeline(steps=[('prep_1', StandardScaler(copy...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_None</th>\n",
       "      <td>-0.110075</td>\n",
       "      <td>0.00755069</td>\n",
       "      <td>-0.0790476</td>\n",
       "      <td>0.000775603</td>\n",
       "      <td>0.176921</td>\n",
       "      <td>{'est__C': 19.8577695762}</td>\n",
       "      <td>Pipeline(steps=[('est', SVR(C=19.8577695762465...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_standard_scaler</th>\n",
       "      <td>-0.179369</td>\n",
       "      <td>0.00911402</td>\n",
       "      <td>-0.139811</td>\n",
       "      <td>0.00314456</td>\n",
       "      <td>0.0514906</td>\n",
       "      <td>{'est__max_features': 9, 'est__min_samples_lea...</td>\n",
       "      <td>Pipeline(steps=[('prep_1', StandardScaler(copy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_min_max</th>\n",
       "      <td>-0.181291</td>\n",
       "      <td>0.0112426</td>\n",
       "      <td>-0.139356</td>\n",
       "      <td>0.00332434</td>\n",
       "      <td>0.0503104</td>\n",
       "      <td>{'est__max_features': 9, 'est__min_samples_lea...</td>\n",
       "      <td>Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_None</th>\n",
       "      <td>-0.182032</td>\n",
       "      <td>0.0136991</td>\n",
       "      <td>-0.139598</td>\n",
       "      <td>0.00374242</td>\n",
       "      <td>0.0434263</td>\n",
       "      <td>{'est__max_features': 9, 'est__min_samples_lea...</td>\n",
       "      <td>Pipeline(steps=[('est', RandomForestRegressor(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_standard_scaler</th>\n",
       "      <td>-0.205662</td>\n",
       "      <td>0.0164844</td>\n",
       "      <td>-0.170119</td>\n",
       "      <td>0.0026078</td>\n",
       "      <td>0.00167966</td>\n",
       "      <td>{'est__n_neighbors': 6}</td>\n",
       "      <td>Pipeline(steps=[('prep_1', StandardScaler(copy...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_min_max</th>\n",
       "      <td>-0.208932</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>-0.177899</td>\n",
       "      <td>0.00214726</td>\n",
       "      <td>0.000760865</td>\n",
       "      <td>{'est__n_neighbors': 7}</td>\n",
       "      <td>Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_None</th>\n",
       "      <td>-0.226435</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>-0.19393</td>\n",
       "      <td>0.00169686</td>\n",
       "      <td>0.000844598</td>\n",
       "      <td>{'est__n_neighbors': 7}</td>\n",
       "      <td>Pipeline(steps=[('est', KNeighborsRegressor(al...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ls_None</th>\n",
       "      <td>-0.498068</td>\n",
       "      <td>0.0258725</td>\n",
       "      <td>-0.497774</td>\n",
       "      <td>0.00289405</td>\n",
       "      <td>0.00531008</td>\n",
       "      <td>{'est__alpha': 3.9241479551}</td>\n",
       "      <td>Pipeline(steps=[('est', Lasso(alpha=3.92414795...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ls_min_max</th>\n",
       "      <td>-0.498068</td>\n",
       "      <td>0.0258725</td>\n",
       "      <td>-0.497774</td>\n",
       "      <td>0.00289405</td>\n",
       "      <td>0.000574732</td>\n",
       "      <td>{'est__alpha': 3.9241479551}</td>\n",
       "      <td>Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ls_standard_scaler</th>\n",
       "      <td>-0.498068</td>\n",
       "      <td>0.0258725</td>\n",
       "      <td>-0.497774</td>\n",
       "      <td>0.00289405</td>\n",
       "      <td>0.00473421</td>\n",
       "      <td>{'est__alpha': 3.9241479551}</td>\n",
       "      <td>Pipeline(steps=[('prep_1', StandardScaler(copy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   best_test_score_mean best_test_score_std train_score_mean  \\\n",
       "sv_min_max                    -0.057709          0.00600658       -0.0536805   \n",
       "sv_standard_scaler            -0.101593           0.0072925       -0.0664077   \n",
       "sv_None                       -0.110075          0.00755069       -0.0790476   \n",
       "rf_standard_scaler            -0.179369          0.00911402        -0.139811   \n",
       "rf_min_max                    -0.181291           0.0112426        -0.139356   \n",
       "rf_None                       -0.182032           0.0136991        -0.139598   \n",
       "kn_standard_scaler            -0.205662           0.0164844        -0.170119   \n",
       "kn_min_max                    -0.208932              0.0163        -0.177899   \n",
       "kn_None                       -0.226435            0.016165         -0.19393   \n",
       "ls_None                       -0.498068           0.0258725        -0.497774   \n",
       "ls_min_max                    -0.498068           0.0258725        -0.497774   \n",
       "ls_standard_scaler            -0.498068           0.0258725        -0.497774   \n",
       "\n",
       "                   train_score_std   score_time  \\\n",
       "sv_min_max             0.000789498    0.0355775   \n",
       "sv_standard_scaler     0.000620663    0.0385854   \n",
       "sv_None                0.000775603     0.176921   \n",
       "rf_standard_scaler      0.00314456    0.0514906   \n",
       "rf_min_max              0.00332434    0.0503104   \n",
       "rf_None                 0.00374242    0.0434263   \n",
       "kn_standard_scaler       0.0026078   0.00167966   \n",
       "kn_min_max              0.00214726  0.000760865   \n",
       "kn_None                 0.00169686  0.000844598   \n",
       "ls_None                 0.00289405   0.00531008   \n",
       "ls_min_max              0.00289405  0.000574732   \n",
       "ls_standard_scaler      0.00289405   0.00473421   \n",
       "\n",
       "                                                          best_params  \\\n",
       "sv_min_max                                  {'est__C': 19.8577695762}   \n",
       "sv_standard_scaler                           {'est__C': 9.8360275689}   \n",
       "sv_None                                     {'est__C': 19.8577695762}   \n",
       "rf_standard_scaler  {'est__max_features': 9, 'est__min_samples_lea...   \n",
       "rf_min_max          {'est__max_features': 9, 'est__min_samples_lea...   \n",
       "rf_None             {'est__max_features': 9, 'est__min_samples_lea...   \n",
       "kn_standard_scaler                            {'est__n_neighbors': 6}   \n",
       "kn_min_max                                    {'est__n_neighbors': 7}   \n",
       "kn_None                                       {'est__n_neighbors': 7}   \n",
       "ls_None                                  {'est__alpha': 3.9241479551}   \n",
       "ls_min_max                               {'est__alpha': 3.9241479551}   \n",
       "ls_standard_scaler                       {'est__alpha': 3.9241479551}   \n",
       "\n",
       "                                                       best_estimator  \\\n",
       "sv_min_max          Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...   \n",
       "sv_standard_scaler  Pipeline(steps=[('prep_1', StandardScaler(copy...   \n",
       "sv_None             Pipeline(steps=[('est', SVR(C=19.8577695762465...   \n",
       "rf_standard_scaler  Pipeline(steps=[('prep_1', StandardScaler(copy...   \n",
       "rf_min_max          Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...   \n",
       "rf_None             Pipeline(steps=[('est', RandomForestRegressor(...   \n",
       "kn_standard_scaler  Pipeline(steps=[('prep_1', StandardScaler(copy...   \n",
       "kn_min_max          Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...   \n",
       "kn_None             Pipeline(steps=[('est', KNeighborsRegressor(al...   \n",
       "ls_None             Pipeline(steps=[('est', Lasso(alpha=3.92414795...   \n",
       "ls_min_max          Pipeline(steps=[('prep_1', MinMaxScaler(copy=T...   \n",
       "ls_standard_scaler  Pipeline(steps=[('prep_1', StandardScaler(copy...   \n",
       "\n",
       "                   best_draw_idx  \n",
       "sv_min_max                     3  \n",
       "sv_standard_scaler             2  \n",
       "sv_None                        3  \n",
       "rf_standard_scaler             1  \n",
       "rf_min_max                     1  \n",
       "rf_None                        1  \n",
       "kn_standard_scaler             4  \n",
       "kn_min_max                     3  \n",
       "kn_None                        3  \n",
       "ls_None                        1  \n",
       "ls_min_max                     1  \n",
       "ls_standard_scaler             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.summary_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
